# Train, Test and Validation Set

After the data analysis of the data, we might end up having multiple models to fit the data, but which model will be best suited for the data and which model needs tweaking to better fit the data is still unknown.

Thus generally we always divide our dataset into 3 separate categories. These categories have separate reasons to help us choose the best model.

## Train Dataset

This is usually the biggest of all the dataset. We usually reserve 70% to 80% of the data as the train set. This dataset is used to train all the models so that during comparison we have the same base conditions to properly compare the models.

> Precaution must be taken that the dataset does not contain dense datapoints for a specific condition i.e in case of Regression problems, the dataset should not have too many data points for 1 set of conditions and too less data points for other sets of conditions. In case of a Classification problem, the data points should be nearly equal for all classes and not too many for 1 class and too less for other classes. Failing to achieve this normalization will result into a biased model, which will favor the majority scenarios over the minority ones.

## Validation Set

Validation set is the next in line after the training set. We generally reserve 10% to 20% for this set.    

This set is mainly useful to check how our model performs on unseen data after training. Poor performance on the validation set might indicate underfitting or overfitting.

Generally if the model performs very well on the training set but poorly on the validation set, it denotes Overfitting.

If the model performs poorly on the training set as well as the validation set, it indicates Underfitting.

Validation set can also be used to tune the hyperparameters. Based on the performance of the model on the validation set, we can nudge the hyperparameters appropriately so that the model performs better after training on the validation set.

> Note: The normalizing condition which was applicable to the training set also applies to the validation set so that we can clearly identify how the model performs over the whole range of possible unseen data once it is done with training.

## Test Set

Once we are done with the training and validation of the models, we will perform the testing of the models. The testing dataset is usually the  5% to 10% in size. It is usually kept small. This dataset is not shown to the model either during training or validation so that we can have an estimate on how the model will perform on real world data. 

As the training dataset and validation dataset are visible to the programmer and model during the training and tweaking process, we don't generally take the performance on these data equivalent to the real world performance because we are constantly nudging the model to better fit these datasets.

The performance of the model on the testing data can be used to select the best model out of a list of models if we end up with multiple good performing models on the validation dataset.
