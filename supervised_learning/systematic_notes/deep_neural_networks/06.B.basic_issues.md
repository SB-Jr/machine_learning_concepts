# Neural Network Issues

There are certain issues which we need to address so as to get proper results in a neural network implementation. These factors affect a neural network to an extent that if not addressed might result in no learning by a neural network.

These factors are:

- Vanishing and Exploding Gradients

- Symmetry of weights

## Vanishing and Exploding Gradients

When we are using backpropagation to calculate the gradients, we tend to use the chain rule to find the values upto the 1st hidden layer.

The chain rule is basically the multiplication of the various partial derivatives.

> If the terms used are large then multiplying the values at some point can reach way to high value thus known as the exploding gradients.

> On the other hand if the values are way too small, the multiplications will result in a further smaller numbers thus leading to near 0 value also known as vanishing gradients.

The main reason why these are an issue is because when we are programming these in python, we will either end up with a Nan value for exploding gradients or 0 for vanishing gradients. This in turn doesn't help the model learn properly and thus might cause issues in fitting the dataset.

These can be the tipping points for letting us know if we have either of these issues:

For exploding gradients:

- Model will have large changes in loss with each iteration

- Model loss will soon become Nan during training

- Model weights are way too high and sometimes become Nan

- Derivatives are constant in each iteration

- Model doesn't learn much even with large dataset resulting in poor performance in training phase

For vanishing gradients:

- Model weights soon achieve 0 value

- The weights near the output will have drastic changes whereas the weights for layer near the input will hardly have any changes in each iteration

- Model will either improve very slowly or will stop early as the loss soon achieves 0 and no changes are detected in loss.

### Basic Solution to these situations are:

- Reducing the Layers of the network

- Gradient clipping i.e. limiting the values the gradient can take. Mainly used for Exploding gradients

- Careful weight initialization can help reduce vanishing gradients but can help with exploding gradients only partially.



## Symmetry of Weights

Another issue that haunts a neural network performance is the symmetry of weights. When we don't initialize weights to random values or we initialize all the weights to the same value i.e. some constant $c$, there is no differentiating factors between the hidden units in the same layer. This results in all the units to learn the same function from the previous layer as rest of the computation of each hidden unit is the same i.e $A_{i-1}^T \cdot W + b$. Thus the hidden units fail to recognize different patterns and becomes similar to a hidden layer with 1 unit.

This can be resolved by using a random variable to sample values to initialize the weights or some other methods to assign differentiating weights for each unit.



### Xavier Initialization

If we use a random variable to sample the weight initialization, we can observe that the randomly initialized weights modify the variance as a result of which the actual variance in the data is not propagated to the output and back properly. If we calculate the variance of 1 layer we can see that, for layer $i$ with $n_{in}$ number of units and $j$ representing each unit:

$$
o_i = \sum_j^{n_{in}} x_i * w_{ij}
$$

$$
\begin{aligned}
Var[o_i] &= E[output_i^2] - E[output_i]^2 \\
&= \sum_j^{n_{in}} E[x_i^2 * w_{ij}^2] - 0 \\
&= \sum E[x_i^2]E[w_{ij}^2] \\
&= n_{in} \gamma^2 \sigma^2
\end{aligned}
$$

Assumptions

- E[X] = 0 i.e. we have normalized the input to have 0 mean

- $E[w_{i}] = 0$ i.e. we have chosen the weights from a distribution whose mean is 0

Where 

- $n_{in}$ is the no of input,

- $\gamma^2$ is the variance of the input

- $\sigma^2$ is the variance of the output at layer $i$ 

As we can see that if we don't control the variance of the weights, it can blow up and cause gradient explosion.

> Another thing to note here is that by just using a 0 mean and unit variance weight distribution actually doesn't help us, as the $n_{in}$ also affects the variance of the output of each layer.

So for us to be able to propagate the variance of the input to the output node without introducing other factors by our model, we need to control the variance of the weights as well.

A simple way to control the variance is to make sure that $n_{in}\sigma^2 = 1$

But when we are backpropagating we get the term $n_{out}\sigma^2$ and so again if we don't control the variance, we might either end up gradient explosion or a modified variance. 

Similarly to control this we can make sure that $n_{out}\sigma^2 = 1$

But we can't satisfy both the conditions simultaneously.

This is where the Xavier Initialization comes into picture. It tries to control the variance introduced by our model by maintaining the fact that the average of both the equation is satisfied as a middle ground, i.e.

$$
\frac{1}{2}(n_{in} + n+{out})\sigma^2 = 1
$$

This ensures that neither the gradient explosion occurs nor the modification introduced is significantly high. This gives us the equation:(if we rearrange the above average)

$$
\sigma = \sqrt{\frac{2}{n_{in}+n_{out}}}
$$

By maintaining the variance of the weights in this manner we overcome both the issues.

> Note: Here we didn't consider that the input is using Gaussian distribution. So we can use any distribution as long as we maintain this distribution's  mean as 0 and variance as stated above.





# Reference

[1]: <https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11> "Vanishing and Exploding gradients"

[2]: <(http://d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html)> "Numerical Stability and Initialization"
