# Object Detection

Object detection is similar to image classification but also at the same time provides a bounding box to identify the region of interest and the class the object inside the bounding box belongs to.

There can be multiple objects in the same image or none. This is done by the object detection algorithms by segmenting the image into multiple subset of pixels and then trying to assign a class to each of them. Once this process is done for all sub-regions of the image, it then tries to perform the union operation on these subsets to find a bigger region inside which max pixels signify the presence of a single class. The perimeter of this region is then provided with a border or also called as a bounding box.

## Methods

- SVM
  
    - Region proposal
  
    - Feature extraction of regions
  
    - Image classification of regions using SVM
  
    - No maxima suppression of identical bounding boxes

- Neural network
  
    - Similar initial steps as SVM
  
    - Using Neural Networks like CNN for classification

- Complex Neural Networks
  
    - Region proposal using network or some complex algorithm tuned for CNN
  
    - CNN classification of regions
  
    - Non Maxima suppression if required
  
    - eg: R-CNN, Faster R-CNN, RetinaNet, Single Shot Detectors, YOLO etc

- 

## Region Proposal

Different models have different ways to sample the regions.

- **Naive Method**: We can split the image into multiple parts and then run a classifier on each part. This introduces more computation and also if the part contains only a segment of the object to be detected then it might miss-classify. This is also computationally expensive.

- **Sliding Window**: We can have a window of fixed length which can slide over the image some pixels at a time and we can then run the classifier on each window. This solves the problem in the previous method of parts only containing fragments of object to some extent. But if the window is not big enough to capture the whole object even when slide to the right position then also we will have the issue of miss-classification and is also computationally expensive.

- **Selective Search**: We can use the image information like the similarity of colors and similarity of textures to detect regions of interest and then only run the classifier on such regions. But this selective search is also time consuming and thus not always preferred.

- **Region Proposal Network**: Here we use another model to search for regions of interest and then provide this selective regions to the classification model to classify the presence of any objects. The downside here is that the outcome now depends on the accuracy of 2 models and just 1. If a region which doesn't contain any object is then provided by the 1st model to the 2nd model, our 2nd model will falsely classify the outcome of 1st model as a label.

## Pipeline

The pipeline of an object detection task is quite different compared to a standard image classification task. Compared to image classification where we input images with labels for training and in inference we expect the output to denote the class number of the highest probable class detected by the network.

In case of object detection training:

- Input is Images 
  
    - Corresponding to each image we have a list of the x,y coordinates of bounding boxes and its width and height
  
    - Corresponding to each bounding box we have the label of the object it is used to identify

- Output is a 
  
    - list of x, y coordinates of bounding boxes and 
  
    - the label it represents

In case of inference:

- Input is image

- Output is a list of 3 values
  
    - List of x, y coordinates of bounding box of all the objects present and the height and width of the bounding box
  
    - The label of the object present inside the bounding box
  
    - the probability score of the label that it tries to represent using the bounding box.

# Reference

[1]: <https://medium.com/@zhao.nathan/understanding-objectness-in-object-detection-models-5d8c9d032488>
